#!/usr/bin/env python
# -*- coding: utf-8 -*-

#
# This template is a very minimal example. Look at the ATAC-seq or
# RNA-seq files for more realistic starting points for your own
# analysis templates.
#

from __future__ import print_function

import collections
import functools
import os


DEFAULT_DIRECTORY_MODE = 0750

ANALYSIS_NAME = "{{ANALYSIS_NAME}}"
DESCRIPTION = """{{DESCRIPTION}}"""
CONTROL_PATH = "{{CONTROL_PATH}}"
ANALYSIS_PATH = "{{ANALYSIS_PATH}}"
DATA_PATH = os.path.join(ANALYSIS_PATH, 'data')
WORK_PATH = os.path.join(ANALYSIS_PATH, 'work')
PIPELINE = os.path.join(ANALYSIS_PATH, 'pipeline')

# By default, we use ionice and limit the number of particularly
# I/O-intensive jobs that run at once, to keep the machine
# responsive. If you're running on dedicated cluster nodes, you
# probably want to set this to False.
LIMIT_IO = 8


#
# The following are generic support functions. They shouldn't need
# tweaking, but feel free.
#


def maybe_gzip(filename, limit_io=LIMIT_IO):
    """Compress a file with gzip."""
    template_data = {
        'f': filename,
        'ionice': limit_io and 'ionice -c2 -n7 ' or ''
    }

    command_template = """if [ -r "{f}" ]; then {ionice}gzip -f "{f}"; elif [ -r "{f}".gz ]; then echo '"{f}" already gzipped.'; fi"""

    printp(command_template.format(**template_data))


def mkdir(dir, mode=DEFAULT_DIRECTORY_MODE):
    """Construct a directory hierarchy using the given permissions."""
    if not os.path.exists(dir):
        os.makedirs(dir, mode)


def print_to_pipeline(pipeline_file, text=None, timed=False, ioniced=False):
    """The primary function of all this: writing to a drmr script."""
    if text:
        if timed:
            pipeline_file.write('/usr/bin/time -v ')
        if ioniced:
            pipeline_file.write('ionice -c2 -n7 ')
        pipeline_file.write(text)
        pipeline_file.write('\n')


def symlink(source_path, dest_path):
    """Create a symbolic link from the source_path to the dest_path, which can be a directory."""

    dest = dest_path
    print('SOURCE: {} DEST: {} DEST_PATH: {}'.format(source_path, dest, dest_path))
    dest_base = os.path.basename(dest)
    if os.path.isdir(dest_path):
        dest = os.path.join(dest_path, os.path.basename(source_path))
        print('DEST: {} DEST_PATH: {}'.format(dest, dest_path))
        if os.path.lexists(dest):
            os.unlink(dest)
        os.symlink(source_path, dest)
    else:
        mkdir(os.path.dirname(dest_path))
        if os.path.lexists(dest):
            os.unlink(dest)
        os.symlink(source_path, dest)
    return dest, dest_base


if __name__ == '__main__':
    print('Creating DATA_PATH {}'.format(DATA_PATH))
    mkdir(DATA_PATH)
    mkdir(WORK_PATH)

    if os.path.exists(PIPELINE):
        os.unlink(PIPELINE)

    PIPELINE_FILE = open(PIPELINE, 'w')
    printp = functools.partial(print_to_pipeline, PIPELINE_FILE)

    printp("""#!/bin/bash""")
    printp("""# -*- mode: sh; coding: utf-8 -*-\n""")

    #
    # The rest of your pipeline goes here.
    #
