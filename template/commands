#!/bin/bash
# -*- mode: sh; coding: utf-8 -*-

set -e  # exit upon any error

function printp() {
    printf "$1\n" >> $PIPELINE
}

ANALYSIS_NAME="{{ANALYSIS_NAME}}"
ANALYSIS_BASENAME="{{ANALYSIS_NAME}}"
ANALYSIS_SUBJECT="{{ANALYSIS_NAME}} SUBJECT NOT SPECIFIED"
ANALYSIS_GROUP="{{ANALYSIS_NAME}} GROUP NOT SPECIFIED"

LAB="${LAB:-/nfs/scjp1/lab}"
CONTROL_PATH="{{CONTROL_PATH}}"
ANALYSIS_PATH="{{ANALYSIS_PATH}}"
DATA="${ANALYSIS_PATH}/data"
WORK="${ANALYSIS_PATH}/work"
PIPELINE="${ANALYSIS_PATH}/pipeline"

mkdir -p ${DATA}
mkdir -p ${WORK}

rm -f $PIPELINE
printp "#!/bin/bash"
printp "# -*- mode: sh; coding: utf-8 -*-\n"

#
# Link initial data into the analysis directory -- uncomment and adjust
#

# ln -s /lab/data/.../datadir/*.fq.gz ${DATA}/

#
# Example pipeline stages follow -- copy, uncomment and edit as necessary.
#

# # --- start example
# printp "\n#\n# trim adapter sequence from reads\n#\n"
# TRIM_ADAPTER_DIR=${WORK}/trim_adapters
# mkdir -p ${TRIM_ADAPTER_DIR}
# printp "# swarm:pbs output_directory=${TRIM_ADAPTER_DIR}\n"

# for r1 in ${DATA}/*_R1_*[0-9].fastq.gz  # for each file of first reads...
# do
#     r2=$(echo $r1 | sed 's/_R1_/_R2_/')  # infer the name of the file of second reads
#     l1=$(basename $r1)
#     l2=$(basename $r2)
#     ln -sf $r1 ${TRIM_ADAPTER_DIR}/$l1
#     ln -sf $r2 ${TRIM_ADAPTER_DIR}/$l2
#     printp "trim_adapters ${TRIM_ADAPTER_DIR}/$l1 ${TRIM_ADAPTER_DIR}/$l2"
# done
# printp "\n# swarm:wait\n"

# printp "#\n# align the reads to the reference genome\n#\n"
# THREADS=4
# REF=${LAB}/data/index/bwa/0.7.12/human/hg19/hg19
# BWA_DIR=${WORK}/bwa
# mkdir -p $BWA_DIR

# printp "# swarm:pbs nodes=nodes=1:ppn=2 output_directory=$BWA_DIR\n"

# for r in ${DATA}/*[0-9].fastq.gz
# do
#     t=$(echo $r | sed 's/.fastq.gz/.trimmed.fastq.gz/')
#     l=$(basename $t)
#     aln="$(echo $l | sed 's/.trimmed.fastq.gz//').sai"
#     ln -sf $t ${BWA_DIR}/$l
#     printp "bwa aln -t ${THREADS} -f ${BWA_DIR}/$aln $REF $l"
# done
# # --- end example
