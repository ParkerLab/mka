#!/usr/bin/env python

#
# This commands template needs customization wherever you see CHANGES
# REQUIRED. Where you see CHANGES RECOMMENDED, check that section to
# make sure it works for your pipeline.
#

from __future__ import print_function

import functools
import os


DEFAULT_DIRECTORY_MODE = 0750

ANALYSIS_NAME = "{{ANALYSIS_NAME}}"
ANALYSIS_BASENAME = "{{ANALYSIS_NAME}}"
ANALYSIS_SUBJECT = "{{ANALYSIS_NAME}} SUBJECT NOT SPECIFIED"
ANALYSIS_GROUP = "{{ANALYSIS_NAME}} GROUP NOT SPECIFIED"

CONTROL_PATH = "{{CONTROL_PATH}}"
ANALYSIS_PATH = "{{ANALYSIS_PATH}}"
DATA_PATH = os.path.join(ANALYSIS_PATH, 'data')
WORK_PATH = os.path.join(ANALYSIS_PATH, 'work')
PIPELINE = os.path.join(ANALYSIS_PATH, 'pipeline')

# By default, we use ionice and limit the number of particularly
# I/O-intensive jobs that run at once, to keep the machine
# responsive. If you're running on dedicated cluster nodes, you
# probably want to set this to False.
LIMIT_IO = True


#
# The following are generic support functions. They shouldn't need
# tweaking, but feel free.
#


def maybe_gzip(filename, limit_io=LIMIT_IO):
    """Compress a file with gzip."""
    template_data = {
        'f': filename,
        'ionice': limit_io and 'ionice -c 3 ' or ''
    }

    command_template = """if [ -r "{f}" ]; then {ionice}gzip -f "{f}"; elif [ -r "{f}".gz ]; then echo '"{f}" already gzipped.'; fi"""

    printp(command_template.format(**template_data))


def mkdir(dir, mode=DEFAULT_DIRECTORY_MODE):
    """Construct a directory hierarchy using the given permissions."""
    if not os.path.exists(dir):
        os.makedirs(dir, mode)


def print_to_pipeline(pipeline_file, text=None, timed=False, ioniced=False):
    """The primary function of all this: writing to a drmr script."""
    if text:
        if timed:
            pipeline_file.write('/usr/bin/time -v ')
        if ioniced:
            pipeline_file.write('ionice -c3 ')
        pipeline_file.write(text)
        pipeline_file.write('\n')


def symlink(source_path, dest_path):
    """Create a symbolic link from the source_path to the dest_path, which can be a directory."""

    dest = dest_path
    dest_base = os.path.basename(dest)
    if os.path.isdir(dest_path):
        dest = os.path.join(dest_path, os.path.basename(source_path))
        if os.path.lexists(dest):
            os.unlink(dest)
        os.symlink(source_path, dest)
    else:
        mkdir(os.path.dirname(dest_path))
        if os.path.lexists(dest):
            os.unlink(dest)
        os.symlink(source_path, dest)
    return dest, dest_base


#
#  End of generic, beginning of analysis-specific functions.
#


def iterate_samples(data, group=None):
    if group:
        for sample in sorted(data.get(group, [])):
            yield '.'.join([group, sample])
    else:
        for group, samples in sorted(data.items()):
            for sample in sorted(samples):
                yield '.'.join([group, sample])


def iterate_original_bam_paths():
    for group, samples in sorted(NISC_SAMPLES.items()):
        for sample in sorted(samples):
            yield os.path.join(SOURCE_DATA_PATH, sample + '.bam')


def iterate_bam_paths():
    for group, samples in sorted(NISC_SAMPLES.items()):
        for sample in sorted(samples):
            yield os.path.join(DATA_PATH, '.'.join([group, sample, 'bam']))


def sample_fastq_files(sample):
    fastq1 = '.'.join([sample, '1.fq.gz'])
    fastq2 = '.'.join([sample, '2.fq.gz'])
    return fastq1, fastq2


def iterate_fastq_filenames():
    for group, samples in sorted(NISC_SAMPLES.items()):
        for sample in sorted(samples):
            yield sample_fastq_files('.'.join([group, sample]))


def star(work_dir, label, command_template=None, threads=4, memory=32):
    if command_template is None:
        command_template = """ionice -c3 STAR --runThreadN {} --readFilesCommand gunzip -c --genomeDir {} --outSAMtype BAM SortedByCoordinate --outSAMunmapped Within KeepPairs --readFilesIn {} {}"""

    printp('\n# drmr:label align-{}-reads'.format(label))

    for group, genome_dir in sorted(GENOME_DIRECTORIES.items()):
        for sample in iterate_samples(group):
            fastq1, fastq2 = map(functools.partial(os.path.join, FASTQ_DIR), sample_fastq_files(sample))
            sample_dir = os.path.join(work_dir, sample)
            mkdir(sample_dir)
            printp('\n# drmr:job time_limit=4h processors={} memory={}g working_directory={}'.format(threads, memory, sample_dir))
            printp(command_template.format(threads, genome_dir, fastq1, fastq2))


def merge_sample_alignments(star_dir, output_dir):
    printp('\n# drmr:job time_limit=2h memory=4g working_directory={}'.format(output_dir))
    for plot_group, plot_group_map in QORTS_PLOT_GROUPS.items():
        for group, samples in plot_group_map.items():
            merged_bam = os.path.join(output_dir, '{}.{}'.format(plot_group, group), 'Aligned.sortedByCoord.out.bam')
            mkdir(os.path.dirname(merged_bam))
            group_bams = [os.path.join(star_dir, sample, 'Aligned.sortedByCoord.out.bam') for sample in samples]
            printp('ionice -c3 samtools merge -f {} {}'.format(merged_bam, ' '.join(group_bams)))


def qorts(genome_dir, input_dir, output_dir, title, command_template=None, threads=4, memory=9):
    if command_template is None:
        command_template = """ionice -c3 java -Xmx8g -jar ${{QORTS_JAR}} QC --stranded --stranded_fr_secondstrand --generatePlots --title {} --chromSizes {} {} {} {}"""

    chrom_sizes = os.path.join(genome_dir, 'chrNameLength.txt')
    gtf = os.path.join(genome_dir, 'annotation.gtf')
    bam = os.path.join(input_dir, 'Aligned.sortedByCoord.out.bam')

    mkdir(output_dir)
    printp('\n# drmr:job time_limit=2h processors={} memory={}g working_directory={}'.format(threads, memory, output_dir))
    printp(command_template.format(title, chrom_sizes, bam, gtf, output_dir))


def qorts_wig2bigwig(genome_dir, working_dir, command_template=None, memory=1):
    if command_template is None:
        command_template = """ionice -c3 wigToBigWig {wig} {chrom_sizes} {bigwig}"""

    chrom_sizes = os.path.join(genome_dir, 'chrNameLength.txt')
    wigs = ['QC.wiggle.fwd.wig.gz', 'QC.wiggle.rev.wig.gz']
    bigwigs = ['QC.wiggle.fwd.bw', 'QC.wiggle.rev.bw']

    printp('\n# drmr:job time_limit=1h processors=1 memory={}g working_directory={}'.format(memory, working_dir))
    for wig, bigwig in zip(wigs, bigwigs):
        printp(command_template.format(**locals()))


#
# End of analysis-specific functions.
#


# An example pipeline follows. You can delete everything after this
# point, if it doesn't suit your needs.

# CHANGES REQUIRED
LAB = '/nfs/turbo/parkerlab1/lab'
SOURCE_DATA_PATH = os.path.join(LAB, 'data/nih/2016_02_nisc-eRNA-CAGE')

HG19_REFERENCE_DIR = os.path.join(LAB, 'data/reference/human/hg19')
MM9_REFERENCE_DIR = os.path.join(LAB, 'data/reference/mouse/mm9')
RN5_REFERENCE_DIR = os.path.join(LAB, 'data/reference/rat/rn5')

HG19_STAR_GENOME_DIR = os.path.join(HG19_REFERENCE_DIR, 'index/STAR/2.5.1b')
MM9_STAR_GENOME_DIR = os.path.join(MM9_REFERENCE_DIR, 'index/STAR/2.5.1b')
RN5_STAR_GENOME_DIR = os.path.join(RN5_REFERENCE_DIR, 'index/STAR/2.5.1b')

ADAPTER5 = 'ACACGACGCTCTTCCGATCT'
ADAPTER5_COMPLEMENT = 'TGTGCTGCGAGAAGGCTAGA'
ADAPTER3 = 'AGATCGGAAGAGCACACGTCTGAACTCC'
ADAPTER3_COMPLEMENT = 'TCTAGCCTTCTCGTGTGCAGACTTGAGG'

#
# Data definitions
#

# The DATA hierarchy is used to group analysis products. It can be a
# single level, mapping your analysis name to a single list
# representing the sequence files, or you can make it as complex a
# tree as necessary, e.g. organism -> cell type -> sample -> file

# The hierarchy can be used to roll up analysis products from lower
# levels. For example, the BAM files from aligning the reads in the
# individual files can be merged into one BAM file per sample. Those
# can then be rolled up into a file per cell type, and so on.
#
# The bottom of the tree controls file naming; it's assumed that each
# string in the bottom lists is the root of a FASTQ file in
# SOURCE_DATA_PATH, and subsequent analysis products will be named
# after those. In the example data, the original FASTQ files
# containing paired-end reads look like ACINAR2_SRR3048051_1.fq.gz,
# ACINAR2_SRR3048051_2.fq.gz, and so on.
#
# This example comes from a moderately complex analysis (the ATAC-seq
# data from Ackerman et al., Molecular Metabolism January 2016), with
# several cell types, each with several samples, each of which was
# split into two libraries and run on a different sequencer. The data
# is available at:
#
# https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE76268
#

#
# CHANGES REQUIRED

NISC_SAMPLES = {
    'e1_min6_total': [
        '160222_OPTIMUS_C855RANXX.3.11973086',
        '160222_OPTIMUS_C855RANXX.4.11973086',
        '160225_ROSIE_C852UANXX.5.11973086',
    ],

    'e2_min6_nuclear': [
        '160222_OPTIMUS_C855RANXX.3.11973084',
        '160222_OPTIMUS_C855RANXX.4.11973084',
        '160225_ROSIE_C852UANXX.5.11973084',
    ],

    'e3_endoc_total': [
        '160222_OPTIMUS_C855RANXX.3.11973090',
        '160222_OPTIMUS_C855RANXX.4.11973090',
        '160225_ROSIE_C852UANXX.5.11973090',
    ],

    'e4_endoc_nuclear': [
        '160222_OPTIMUS_C855RANXX.3.11973096',
        '160222_OPTIMUS_C855RANXX.4.11973096',
        '160225_ROSIE_C852UANXX.5.11973096',
    ],

    'e5_83213_total': [
        '160222_OPTIMUS_C855RANXX.3.11973088',
        '160222_OPTIMUS_C855RANXX.4.11973088',
        '160225_ROSIE_C852UANXX.5.11973088',
    ],

    'e6_83213_nuclear': [
        '160222_OPTIMUS_C855RANXX.3.11973082',
        '160222_OPTIMUS_C855RANXX.4.11973082',
        '160225_ROSIE_C852UANXX.5.11973082',
    ],

    'e7_hskm_nuclear': [
        '160222_OPTIMUS_C855RANXX.3.11973094',
        '160222_OPTIMUS_C855RANXX.4.11973094',
        '160225_ROSIE_C852UANXX.5.11973094',
    ],

    'e8_hskm_total': [
        '160222_OPTIMUS_C855RANXX.3.11973092',
        '160222_OPTIMUS_C855RANXX.4.11973092',
        '160225_ROSIE_C852UANXX.5.11973092',
    ]
}

GENOME_DIRECTORIES = {
    'e1_min6_total': MM9_STAR_GENOME_DIR,
    'e2_min6_nuclear': MM9_STAR_GENOME_DIR,
    'e3_endoc_total': HG19_STAR_GENOME_DIR,
    'e4_endoc_nuclear': HG19_STAR_GENOME_DIR,
    'e5_83213_total': RN5_STAR_GENOME_DIR,
    'e6_83213_nuclear': RN5_STAR_GENOME_DIR,
    'e7_hskm_nuclear': HG19_STAR_GENOME_DIR,
    'e8_hskm_total': HG19_STAR_GENOME_DIR,
    'min6': MM9_STAR_GENOME_DIR,
    'endoc': HG19_STAR_GENOME_DIR,
    '83213': RN5_STAR_GENOME_DIR,
    'hsm': HG19_STAR_GENOME_DIR,
}

QORTS_PLOT_GROUPS = {
    'min6': {
        'total': list(iterate_samples('e1_min6_total')),
        'nuclear': list(iterate_samples('e2_min6_nuclear')),
    },
    'endoc': {
        'total': list(iterate_samples('e3_endoc_total')),
        'nuclear': list(iterate_samples('e4_endoc_nuclear')),
    },
    '83213': {
        'total': list(iterate_samples('e5_83213_total')),
        'nuclear': list(iterate_samples('e6_83213_nuclear')),
    },
    'hsm': {
        'total': list(iterate_samples('e8_hskm_total')),
        'nuclear': list(iterate_samples('e7_hskm_nuclear')),
    }
}


if __name__ == '__main__':
    print('Creating DATA_PATH {}'.format(DATA_PATH))
    mkdir(DATA_PATH)

    for source_file, dest in zip(iterate_original_bam_paths(), iterate_bam_paths()):
        print('Linking original NISC BAM file {} to {}'.format(source_file, dest))
        if os.path.exists(dest):
            os.unlink(dest)
            os.symlink(source_file, dest)

    mkdir(WORK_PATH)

    if os.path.exists(PIPELINE):
        os.unlink(PIPELINE)

    PIPELINE_FILE = open(PIPELINE, 'w')
    printp = functools.partial(print_to_pipeline, PIPELINE_FILE)

    printp('#!/bin/bash')
    printp('# -*- mode: sh; coding: utf-8 -*-\n')

    printp('\n#\n# Convert the NISC BAM files to FASTQ\n#')
    FASTQ_DIR = os.path.join(WORK_PATH, 'fastq')
    mkdir(FASTQ_DIR)
    printp('\n# drmr:label fastq')
    printp('\n# drmr:job time_limit=1h working_directory={}'.format(FASTQ_DIR))

    for bam_path in iterate_bam_paths():
        printp('bam2fastq.pl --yes {}'.format(bam_path))

    printp('\n# drmr:wait')

    printp('\n#\n# run FastQC\n#')
    FASTQC_DIR = os.path.join(WORK_PATH, 'fastqc')
    mkdir(FASTQC_DIR)
    printp('\n# drmr:label fastqc')
    printp('\n# drmr:job time_limit=1h working_directory={}'.format(FASTQC_DIR))

    for fastq_pair in iterate_fastq_filenames():
        for fastq in fastq_pair:
            dest, dest_base = symlink(os.path.join(FASTQ_DIR, fastq), FASTQC_DIR)
            printp('ionice -c3 fastqc {}'.format(dest_base))

    printp('\n#\n# trim adapter sequence from reads\n#')
    TRIM_ADAPTER_DIR = os.path.join(WORK_PATH, 'trim_adapters')
    mkdir(TRIM_ADAPTER_DIR)
    printp('\n# drmr:label trim-adapters')
    printp('\n# drmr:job time_limit=1h working_directory={}'.format(TRIM_ADAPTER_DIR))

    for fastq1, fastq2 in iterate_fastq_filenames():
        original1 = os.path.join(FASTQ_DIR, fastq1)
        original2 = os.path.join(FASTQ_DIR, fastq2)
        too_short1 = fastq1.replace('.1.fq.gz', '.tooshort.1.fq.gz')
        too_short2 = fastq2.replace('.2.fq.gz', '.tooshort.2.fq.gz')
        printp('ionice -c3 cutadapt --minimum-length 36 --too-short-output {} --too-short-paired-output {} -a {} -A {} -g {} -g {} --output {} --paired-output {} {} {}\n'.format(
            too_short1, too_short2, ADAPTER3, ADAPTER3_COMPLEMENT, ADAPTER5, ADAPTER5_COMPLEMENT, fastq1, fastq2, original1, original2
        ))

    ALIGN_ORIGINAL_DIR = os.path.join(WORK_PATH, 'align_original')
    mkdir(ALIGN_ORIGINAL_DIR)
    star(ALIGN_ORIGINAL_DIR, 'original')

    ALIGN_TRIMMED_DIR = os.path.join(WORK_PATH, 'align_trimmed')
    mkdir(ALIGN_TRIMMED_DIR)
    star(ALIGN_TRIMMED_DIR, 'trimmed')

    printp('\n# drmr:wait')

    printp('\n#\n# Merge original alignments of each sample\n#')
    printp('\n# drmr:label merge-original-alignments')
    QORTS_ORIGINAL_MERGED_DIR = os.path.join(WORK_PATH, 'qorts_original_merged')
    mkdir(QORTS_ORIGINAL_MERGED_DIR)
    merge_sample_alignments(ALIGN_ORIGINAL_DIR, QORTS_ORIGINAL_MERGED_DIR)

    printp('\n#\n# Merge trimmed alignments of each sample\n#')
    printp('\n# drmr:label merge-trimmed-alignments')
    QORTS_TRIMMED_MERGED_DIR = os.path.join(WORK_PATH, 'qorts_trimmed_merged')
    mkdir(QORTS_TRIMMED_MERGED_DIR)
    merge_sample_alignments(ALIGN_TRIMMED_DIR, QORTS_TRIMMED_MERGED_DIR)

    printp('\n#\n# Run QoRTs QC on original alignments\n#')
    QORTS_ORIGINAL_DIR = os.path.join(WORK_PATH, 'qorts_original')
    mkdir(QORTS_ORIGINAL_DIR)

    printp('\n# drmr:label qorts-original')
    for group, genome_dir in sorted(GENOME_DIRECTORIES.items()):
        for sample in iterate_samples(group):
            input_dir = os.path.join(ALIGN_ORIGINAL_DIR, sample)
            output_dir = os.path.join(QORTS_ORIGINAL_DIR, sample)
            qorts(genome_dir, input_dir, output_dir, sample)

    printp('\n#\n# Run QoRTs QC on trimmed alignments\n#')
    QORTS_TRIMMED_DIR = os.path.join(WORK_PATH, 'qorts_trimmed')
    mkdir(QORTS_TRIMMED_DIR)

    printp('\n# drmr:label qorts-trimmed')
    for group, genome_dir in sorted(GENOME_DIRECTORIES.items()):
        for sample in iterate_samples(group):
            input_dir = os.path.join(ALIGN_TRIMMED_DIR, sample)
            output_dir = os.path.join(QORTS_TRIMMED_DIR, sample)
            qorts(genome_dir, input_dir, output_dir, sample)

    printp('\n#\n# Run QoRTs QC on original alignments of each sample\n#')
    printp('\n# drmr:label qorts-original-merged')
    for plot_group, plot_group_map in QORTS_PLOT_GROUPS.items():
        genome_dir = GENOME_DIRECTORIES[plot_group]
        for group, samples in plot_group_map.items():
            input_dir = output_dir = os.path.join(QORTS_ORIGINAL_MERGED_DIR, '{}.{}'.format(plot_group, group))
            qorts(genome_dir, input_dir, output_dir, '{}_{}'.format(plot_group, group))

    printp('\n#\n# Run QoRTs QC on trimmed alignments of each sample\n#')
    printp('\n# drmr:label qorts-trimmed-merged')
    for plot_group, plot_group_map in QORTS_PLOT_GROUPS.items():
        genome_dir = GENOME_DIRECTORIES[plot_group]
        for group, samples in plot_group_map.items():
            input_dir = output_dir = os.path.join(QORTS_TRIMMED_MERGED_DIR, '{}.{}'.format(plot_group, group))
            qorts(genome_dir, input_dir, output_dir, '{}_{}'.format(plot_group, group))

    printp('\n# drmr:wait')

    printp('\n#\n# Convert wiggle output of QoRTs QC on merged original alignments to bigWig\n#')
    printp('\n# drmr:label qorts-original-bigwig')
    for plot_group, plot_group_map in QORTS_PLOT_GROUPS.items():
        genome_dir = GENOME_DIRECTORIES[plot_group]
        for group, samples in plot_group_map.items():
            working_dir = os.path.join(QORTS_ORIGINAL_MERGED_DIR, '{}.{}'.format(plot_group, group))
            qorts_wig2bigwig(genome_dir, working_dir)
